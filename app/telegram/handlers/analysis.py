import asyncio
import io, logging
import re
from datetime import datetime

import sentry_sdk
from aiogram import Bot, Router, F
from aiogram.filters import Command
from aiogram.fsm.context import FSMContext
from aiogram.fsm.state import StatesGroup, State
from aiogram.types import Message, InlineKeyboardButton, InlineKeyboardMarkup, CallbackQuery
from pydantic import BaseModel

from app.cv_analyzer.static import analyze_resume_text
from app.cv_analyzer.llm import LLMService
from app.dal import MessagesDAL, AnalyticsDAL, UsersDAL, FileCheckingDAL
from app.models import MessageModel, Analysis, MessageType, AnalysisDetail, FileChecking
from app.settings import Settings
from app.storage import save_upload
from app.utils.long_messages import send_long_message
from app.utils.text_parser import extract_text_auto

logger = logging.getLogger(__name__)

analysis_router = Router(name="analyis")

CALLBACK_DATA = "skip_vacancy_details"


class AnalysisScene(StatesGroup):
    resume_waiting = State()
    vacancy_waiting = State()


class DocumentInfo(BaseModel):
    path: str
    data: str


@analysis_router.message(Command("analysis"))
async def analysis(message: Message, state: FSMContext):
    user = await UsersDAL.get_user(message.from_user.id)

    await MessagesDAL.insert(
        MessageModel(
            type=MessageType.COMMAND,
            message_id=message.message_id,
            text=message.text,
            chat_id=message.chat.id,
            user_id=message.from_user.id if message.from_user else "",
        )
    )

    if not user.accepted_rules:
        await message.answer("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø—Ä–∏–º–∏—Ç–µ —Å–æ–≥–ª–∞—à–µ–Ω–∏–µ. –î–ª—è —ç—Ç–æ–≥–æ –≤–æ—Å–ø–æ–ª—å–∑—É–π—Ç–µ—Å—å –∫–æ–º–∞–Ω–¥–æ–π /start")
        return

    # –ü–æ–ª–Ω—ã–π –æ—Ç—á—ë—Ç
    if user.subscription_until < datetime.utcnow() and user.one_time_full_left <= 0:
        await message.answer(
            f"–û–ø–ª–∞—Ç–∏—Ç–µ –ø–æ–¥–ø–∏—Å–∫—É, —á—Ç–æ–±—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –æ—Ç—á—ë—Ç–∞–º–∏ –æ —Ä–µ–∑—é–º–µ. –ö–æ–º–∞–Ω–¥–∞: /subscription"
        )
        return

    await state.set_state(AnalysisScene.resume_waiting)
    await message.answer("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ—Ç–ø—Ä–∞–≤—å—Ç–µ —Ñ–∞–π–ª —Å–≤–æ–µ–≥–æ —Ä–µ–∑—é–º–µ –≤ PDF –∏–ª–∏ DOCX —Ñ–æ—Ä–º–∞—Ç–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞.")


@analysis_router.message(AnalysisScene.resume_waiting, F.document)
async def handle_resume(message: Message, state: FSMContext, bot: Bot, settings: Settings) -> None:
    await message.answer("–ß–∏—Ç–∞–µ–º —Ñ–∞–π–ª...")

    # download bytes
    try:
        resume_info = await get_text_from_message(bot, message, settings.data_dir)
        await MessagesDAL.insert(
            MessageModel(
                type=MessageType.DOCUMENT,
                message_id=message.message_id,
                text="OK",
                chat_id=message.chat.id,
                user_id=message.from_user.id if message.from_user else None,
                file_name=message.document.file_name,
            )
        )

    except:
        await message.answer(
            "–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç –∏–∑ —Ñ–∞–π–ª–∞. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —É–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —ç—Ç–æ PDF –∏–ª–∏ DOCX —Å —Ç–µ–∫—Å—Ç–æ–º. –ò–ª–∏ –æ–±—Ä–∞—Ç–∏—Ç–µ—Å—å –≤ –ø–æ–¥–¥–µ—Ä–∂–∫—É."
        )
        await MessagesDAL.insert(
            MessageModel(
                type=MessageType.DOCUMENT,
                message_id=message.message_id,
                text="ERROR",
                chat_id=message.chat.id,
                user_id=message.from_user.id if message.from_user else None,
                file_name=message.document.file_name,
            )
        )

        raise

    await message.answer("–ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–∞–π–ª...")

    llm_service = LLMService.build(settings.llm_settings)
    try:
        detail = await llm_service.check_resume_is_valid(
            resume_info.data,
        )
    except:
        await message.answer(
            "–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ —Ñ–∞–π–ª–∞. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ –∏–ª–∏ –æ–±—Ä–∞—Ç–∏—Ç–µ—Å—å –≤ –ø–æ–¥–¥–µ—Ä–∂–∫—É."
        )
        raise

    if not detail.is_valid:
        await FileCheckingDAL.insert(FileChecking(
            user_id=message.from_user.id,
            filepath=resume_info.path,
            result=detail,
        ))
        await message.answer(
            f"–ü–æ—Ö–æ–∂–µ, —á—Ç–æ —ç—Ç–æ –Ω–µ —Ä–µ–∑—é–º–µ.\n\n"
            # f"{detail.reason}\n\n"
            "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π —Ñ–∞–π–ª –æ–ø–∏—Å–∞–Ω–∏—è –≤–∞–∫–∞–Ω—Å–∏–∏ —Ç–µ–∫—Å—Ç–æ–º –∏–ª–∏ –≤ PDF/DOCX —Ñ–æ—Ä–º–∞—Ç–µ."
        )
        return

    # save file to analysis documents
    await state.update_data(resume_info=resume_info)

    # Add button to skip vacancy details
    await message.answer(
        "–§–∞–π–ª –ø–æ–ª—É—á–µ–Ω.\n\n"
        "–¢–µ–ø–µ—Ä—å –¥–æ–±–∞–≤—å—Ç–µ, –µ—Å–ª–∏ —Ö–æ—Ç–∏—Ç–µ, –Ω–∞–∑–≤–∞–Ω–∏–µ –≤–∞–∫–∞–Ω—Å–∏–∏ –∏–ª–∏ –µ—ë –æ–ø–∏—Å–∞–Ω–∏–µ. –ú–æ–∂–Ω–æ —Å–¥–µ–ª–∞—Ç—å —Ç–µ–∫—Å—Ç–æ–º –∏–ª–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–º PDF/TXT."
        "–ú–æ–∂–µ—Ç–µ –ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å —ç—Ç–æ—Ç —à–∞–≥ –∏ —Å—Ä–∞–∑—É –ø–æ–ª—É—á–∏—Ç—å –∞–Ω–∞–ª–∏–∑ —Ä–µ–∑—é–º–µ.",
        reply_markup=InlineKeyboardMarkup(inline_keyboard=[[
            InlineKeyboardButton(text="‚è© –ë–µ–∑ –æ–ø–∏—Å–∞–Ω–∏—è –≤–∞–∫–∞–Ω—Å–∏–∏!", callback_data=CALLBACK_DATA)
        ]]),
    )
    await state.set_state(AnalysisScene.vacancy_waiting)


@analysis_router.message(AnalysisScene.vacancy_waiting, F.document)
async def handle_vacancy(message: Message, state: FSMContext, bot: Bot, settings: Settings) -> None:

    await message.answer("–ß–∏—Ç–∞–µ–º —Ñ–∞–π–ª...")

    # download bytes
    try:
        vacancy_info = await get_text_from_message(bot, message, settings.data_dir)
        await MessagesDAL.insert(
            MessageModel(
                type=MessageType.DOCUMENT,
                message_id=message.message_id,
                text="OK",
                chat_id=message.chat.id,
                user_id=message.from_user.id if message.from_user else None,
                file_name=message.document.file_name,
            )
        )
    except:
        await MessagesDAL.insert(
            MessageModel(
                type=MessageType.DOCUMENT,
                message_id=message.message_id,
                text="ERROR",
                chat_id=message.chat.id,
                user_id=message.from_user.id if message.from_user else None,
                file_name=message.document.file_name,
            )
        )
        await message.answer(
            "–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç –∏–∑ —Ñ–∞–π–ª–∞. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —É–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —ç—Ç–æ PDF –∏–ª–∏ DOCX —Å —Ç–µ–∫—Å—Ç–æ–º. –ò–ª–∏ –æ–±—Ä–∞—Ç–∏—Ç–µ—Å—å –≤ –ø–æ–¥–¥–µ—Ä–∂–∫—É."
        )
        raise


    llm_service = LLMService.build(settings.llm_settings)
    try:
        file_checking_result = await llm_service.check_resume_is_valid(
            vacancy_info.data,
        )
    except:
        await message.answer(
            "–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ —Ñ–∞–π–ª–∞. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ –∏–ª–∏ –æ–±—Ä–∞—Ç–∏—Ç–µ—Å—å –≤ –ø–æ–¥–¥–µ—Ä–∂–∫—É."
        )
        raise

    if not file_checking_result.is_valid:
        await FileCheckingDAL.insert(FileChecking(
            user_id=message.from_user.id,
            filepath=vacancy_info.path,
            result=file_checking_result,
        ))
        await message.answer(
            f"–ü–æ—Ö–æ–∂–µ, —á—Ç–æ —ç—Ç–æ –Ω–µ –æ–ø–∏—Å–∞–Ω–∏–µ –≤–∞–∫–∞–Ω—Å–∏–∏.\n\n"
            # f"{file_checking_result.reason}\n\n"
            "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π —Ñ–∞–π–ª —Ä–µ–∑—é–º–µ –≤ PDF –∏–ª–∏ DOCX —Ñ–æ—Ä–º–∞—Ç–µ."
        )
        return

    data = await state.get_data()
    resume_info: DocumentInfo = data.get("resume_info")
    if not resume_info:
        await message.answer("–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –Ω–∞—á–Ω–∏—Ç–µ –∞–Ω–∞–ª–∏–∑ –∑–∞–Ω–æ–≤–æ –∫–æ–º–∞–Ω–¥–æ–π /analysis.")
        await state.clear()
        return

    await process_resume(message, resume_info, vacancy_info, settings)


@analysis_router.message(AnalysisScene.vacancy_waiting)
async def handle_vacancy_text(message: Message, state: FSMContext, bot: Bot, settings: Settings) -> None:
    await MessagesDAL.insert(
        MessageModel(
            type=MessageType.TEXT,
            message_id=message.message_id,
            text=message.text or "",
            chat_id=message.chat.id,
            user_id=message.from_user.id if message.from_user else None,
        )
    )

    data = await state.get_data()
    resume_info: DocumentInfo = data.get("resume_info")
    if not resume_info:
        await message.answer("–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –Ω–∞—á–Ω–∏—Ç–µ –∞–Ω–∞–ª–∏–∑ –∑–∞–Ω–æ–≤–æ –∫–æ–º–∞–Ω–¥–æ–π /analysis.")
        await state.clear()
        return

    await process_resume(message, resume_info, DocumentInfo(path="", data=message.text), settings)


@analysis_router.callback_query(AnalysisScene.vacancy_waiting, F.data == CALLBACK_DATA)
async def handle_skip_vacancy(callback: CallbackQuery, state: FSMContext, settings: Settings) -> None:
    await MessagesDAL.insert(
        MessageModel(
            type=MessageType.CALLBACK,
            message_id=callback.message.message_id if callback.message else -1,
            text="",
            chat_id=callback.message.chat.id if callback.message else -1,
            user_id=callback.from_user.id,
            callback_data=callback.data,
        )
    )

    data = await state.get_data()
    resume_info: DocumentInfo = data.get("resume_info")
    if not resume_info:
        await callback.message.answer("–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –Ω–∞—á–Ω–∏—Ç–µ –∞–Ω–∞–ª–∏–∑ –∑–∞–Ω–æ–≤–æ –∫–æ–º–∞–Ω–¥–æ–π /analysis.")
        await state.clear()
        return

    await process_resume(
        callback.message,
        resume_info,
        DocumentInfo(path="", data=""),
        settings,
    )
    await state.clear()


async def process_resume(message: Message, cv_info: DocumentInfo, vacancy_info: DocumentInfo,
                         settings: Settings) -> None:
    heuristic = analyze_resume_text(cv_info.data)
    score = heuristic.score

    await message.answer("–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–µ–∑—é–º–µ...\n–≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–∏–Ω—É—Ç.")
    try:
        llm_service = LLMService.build(settings.llm_settings)
        detail = await llm_service.full_feedback(
            cv_info.data,
            vacancy_info.data,
        )
    except:
        await message.answer(
            "–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ —Ä–µ–∑—é–º–µ. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ –∏–ª–∏ –æ–±—Ä–∞—Ç–∏—Ç–µ—Å—å –≤ –ø–æ–¥–¥–µ—Ä–∂–∫—É."
        )
        raise

    await AnalyticsDAL.insert(
        Analysis(
            user_id=message.from_user.id,
            filepaths=[cv_info.path, vacancy_info.path],
            details=[detail, heuristic],
        )
    )

    if detail.ok:
        await send_ok_message(detail, message)
    else:
        await send_raw_message(detail, message)

    user = await UsersDAL.get_user(message.from_user.id)
    await UsersDAL.consume_one_time_full(user.tg_user_id)
    await message.answer(
        "–ù–∞ —ç—Ç–æ–º –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –æ–∫–æ–Ω—á–µ–Ω–∞.\n\n"
        "–ï—Å–ª–∏ —Ö–æ—Ç–∏—Ç–µ —É–∑–Ω–∞—Ç—å, –∫–∞–∫ –Ω–∞—à –±–æ—Ç –æ—Ç—Ä–µ–∞–≥–∏—Ä—É–µ—Ç –Ω–∞ –Ω–æ–≤–æ–µ —Ä–µ–∑—é–º–µ, –∫—É–ø–∏—Ç–µ –ø–æ–¥–ø–∏—Å–∫—É. –ö–æ–º–∞–Ω–¥–∞ /subscription"
    )


def _escape_md_v2(text: str) -> str:
    # Telegram MarkdownV2 requires escaping these characters
    return re.sub(r'([_*[\]()~`>#\+\-=|{}\.!])', r'\\\1', text)


async def send_ok_message(detail: AnalysisDetail, message: Message) -> None:
    score_str = str(detail.score) if detail.score is not None else "‚Äî"
    sections: list[str] = [f"*üìä –û—Ü–µ–Ω–∫–∞ —Ä–µ–∑—é–º–µ: {_escape_md_v2(score_str)}/100*"]

    if detail.strengths:
        strengths = "\n".join(f"‚Ä¢ {_escape_md_v2(s)}" for s in detail.strengths)
        sections.append(f"*‚úÖ –°–∏–ª—å–Ω—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã*\n{strengths}")

        full_text = "\n\n".join(sections)
        await send_long_message(message, full_text, parse_mode="MarkdownV2")
        sections = []

    if detail.problems:
        problems = "\n".join(f"‚Ä¢ {_escape_md_v2(p)}" for p in detail.problems)
        sections.append(f"*‚ö†Ô∏è –ü—Ä–æ–±–ª–µ–º—ã*\n{problems}")

        full_text = "\n\n".join(sections)
        await send_long_message(message, full_text, parse_mode="MarkdownV2")
        sections = []

    if detail.actions:
        actions = "\n".join(f"‚Ä¢ {_escape_md_v2(a)}" for a in detail.actions[:10])
        sections.append(f"*üõ† –ß—Ç–æ —Å–¥–µ–ª–∞—Ç—å*\n{actions}")

        full_text = "\n\n".join(sections)
        await send_long_message(message, full_text, parse_mode="MarkdownV2")
        sections = []

    if sections:
        full_text = "\n\n".join(sections)
        await send_long_message(message, full_text, parse_mode="MarkdownV2")


async def send_raw_message(detail: AnalysisDetail, message: Message) -> None:
    sentry_sdk.capture_message(
        f"LLM resume analysis parsing failed for user. {message.from_user.id=} {message.message_id=}",
        level="warning",
    )
    await message.answer(
        "–ù–µ —É–¥–∞–ª–æ—Å—å –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ä–µ–∑—é–º–µ. –í–æ—Ç —á—Ç–æ –≤–µ—Ä–Ω—É–ª–æ LLM (–≤–æ–∑–º–æ–∂–Ω–æ, —Ñ–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞ –Ω–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –æ–∂–∏–¥–∞–µ–º–æ–º—É):"
    )
    await send_long_message(message, _escape_md_v2(detail.raw), parse_mode="MarkdownV2")


async def get_text_from_message(bot: Bot, message: Message, data_dir: str) -> DocumentInfo:
    tg_file = await bot.get_file(message.document.file_id)
    buf = io.BytesIO()
    await bot.download_file(tg_file.file_path, buf)
    data = buf.getvalue()
    filename = message.document.file_name or f"resume_{message.document.file_id}"

    # Save locally
    path = save_upload(data_dir, message.from_user.id, filename, data)

    return DocumentInfo(
        path=path,
        data=extract_text_auto(path),
    )
